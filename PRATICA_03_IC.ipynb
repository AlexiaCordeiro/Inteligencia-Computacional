{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexiaCordeiro/Inteligencia-Computacional/blob/master/PRATICA_03_IC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ],
      "metadata": {
        "id": "wr8oMttwy6FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, subprocess, os, shutil, zipfile, json, warnings\n",
        "\n",
        "def pip_install(pkg):\n",
        "    try:\n",
        "        __import__(pkg.split(\"==\")[0].replace(\"-\", \"_\"))\n",
        "    except Exception:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"])\n",
        "\n",
        "for pkg in [\"pandas\", \"numpy\", \"scikit-learn\", \"joblib\", \"tqdm\", \"kaggle\"]:\n",
        "    pip_install(pkg)"
      ],
      "metadata": {
        "id": "PBVTc1rIw2uY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate # Adicionei o cross validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import shuffle as sk_shuffle\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.decomposition import PCA\n",
        "from joblib import dump\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "a7IUhTS5w4nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exists_all(paths):\n",
        "    return all(os.path.exists(p) for p in paths)\n",
        "\n",
        "def try_kaggle_download(comp=\"santander-customer-transaction-prediction\"):\n",
        "    kaggle_dir = os.path.join(os.path.expanduser(\"~\"), \".kaggle\")\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "    kj_path = os.path.join(kaggle_dir, \"kaggle.json\")\n",
        "    if not os.path.exists(kj_path) and \"KAGGLE_USERNAME\" not in os.environ:\n",
        "        try:\n",
        "            from google.colab import files\n",
        "            print(\"Envie seu kaggle.json (Kaggle > Account > Create New API Token)...\")\n",
        "            uploaded = files.upload()\n",
        "            if uploaded:\n",
        "                up_name = list(uploaded.keys())[0]\n",
        "                shutil.move(up_name, kj_path)\n",
        "                os.chmod(kj_path, 0o600)\n",
        "                print(\"kaggle.json salvo em ~/.kaggle/\")\n",
        "        except Exception:\n",
        "            print(\"Upload não disponível (talvez não esteja no Colab).\")\n",
        "    try:\n",
        "        zip_name = f\"{comp}.zip\"\n",
        "        print(\"Baixando dados via Kaggle API...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"kaggle\", \"competitions\", \"download\", \"-c\", comp])\n",
        "        if os.path.exists(zip_name):\n",
        "            with zipfile.ZipFile(zip_name, \"r\") as zf:\n",
        "                zf.extractall(\".\")\n",
        "            print(\"Arquivos extraídos com sucesso.\")\n",
        "        else:\n",
        "            print(f\"Aviso: {zip_name} não encontrado após o download.\")\n",
        "    except Exception as e:\n",
        "        print(\"\\n[AVISO] Falha no download automático pelo Kaggle.\")\n",
        "        print(\"Possíveis causas: (1) Regras não aceitas; (2) Credenciais ausentes/incorretas.\")\n",
        "        print(\"Alternativas: faça upload manual de train.csv/test.csv/sample_submission.csv para o diretório atual.\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "xL64aVKww6bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auc_acc(y_true, y_prob, y_pred=None):\n",
        "    if y_pred is None:\n",
        "        y_pred = (y_prob >= 0.5).astype(int)\n",
        "    return roc_auc_score(y_true, y_prob), accuracy_score(y_true, y_pred)\n",
        "\n",
        "def evaluate_model(clf, X_tr, y_tr, X_va, y_va):\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    if hasattr(clf, \"predict_proba\"):\n",
        "        y_prob = clf.predict_proba(X_va)[:, 1]\n",
        "    else:\n",
        "        y_prob = clf.decision_function(X_va) if hasattr(clf, \"decision_function\") else clf.predict(X_va).astype(float)\n",
        "    y_pred = clf.predict(X_va)\n",
        "    AUC, ACC = auc_acc(y_va, y_prob, y_pred)\n",
        "    return AUC, ACC, clf\n",
        "\n",
        "def cv_score(clf, X, y, cv=3, scoring=\"roc_auc\"):\n",
        "    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)\n",
        "    aucs = []\n",
        "    for tr_idx, va_idx in skf.split(X, y):\n",
        "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "        y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "        clf.fit(X_tr, y_tr)\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            y_prob = clf.predict_proba(X_va)[:, 1]\n",
        "        else:\n",
        "            y_prob = clf.decision_function(X_va) if hasattr(clf, \"decision_function\") else clf.predict(X_va).astype(float)\n",
        "        aucs.append(roc_auc_score(y_va, y_prob))\n",
        "    return float(np.mean(aucs))\n"
      ],
      "metadata": {
        "id": "kVnYxxBkw8ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search_with_tqdm(estimator_builder, param_grid, X, y, cv=3, desc=\"GridSearch\"):\n",
        "    grid = list(ParameterGrid(param_grid))\n",
        "    best_score, best_params = -np.inf, None\n",
        "    for params in tqdm(grid, desc=desc, total=len(grid)):\n",
        "        clf = estimator_builder(params)\n",
        "        score = cv_score(clf, X, y, cv=cv, scoring=\"roc_auc\")\n",
        "        if score > best_score:\n",
        "            best_score, best_params = score, params\n",
        "    best_estimator = estimator_builder(best_params)\n",
        "    best_estimator.fit(X, y)\n",
        "    return best_estimator, best_params, best_score\n",
        "\n",
        "DATA_FILES = [\"train.csv\", \"test.csv\", \"sample_submission.csv\"]\n",
        "if not exists_all(DATA_FILES):\n",
        "    print(\"Arquivos não encontrados em ./ — tentando baixar do Kaggle.\")\n",
        "    try_kaggle_download()\n",
        "\n",
        "assert exists_all(DATA_FILES), \"Necessário train.csv, test.csv e sample_submission.csv no diretório atual.\"\n",
        "\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test  = pd.read_csv(\"test.csv\")\n",
        "sample_sub = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "assert \"target\" in df_train.columns, \"Coluna 'target' ausente em train.csv\"\n",
        "assert \"ID_code\" in df_train.columns and \"ID_code\" in df_test.columns, \"Coluna 'ID_code' ausente.\"\n",
        "\n",
        "X_full = df_train.drop(columns=[\"ID_code\", \"target\"])\n",
        "y_full = df_train[\"target\"].astype(int)\n",
        "X_test = df_test.drop(columns=[\"ID_code\"])\n",
        "id_test = df_test[\"ID_code\"]\n",
        "\n",
        "print(\"Shapes -> X_full:\", X_full.shape, \"| y_full:\", y_full.shape, \"| X_test:\", X_test.shape)\n",
        "print(\"Proporção classe positiva (train):\", y_full.mean().round(4))\n",
        "\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "    X_full, y_full, test_size=0.2, stratify=y_full, random_state=RANDOM_STATE\n",
        ")\n",
        "print(\"Split local -> Train:\", X_tr.shape, \"| Val:\", X_va.shape)\n",
        "\n",
        "results_baseline = {}\n",
        "\n",
        "tree_base = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=3)\n",
        "AUC, ACC, _ = evaluate_model(tree_base, X_tr, y_tr, X_va, y_va)\n",
        "results_baseline[\"DecisionTree\"] = {\"auc\": AUC, \"acc\": ACC, \"model\": tree_base}\n",
        "\n",
        "nb_base = GaussianNB()\n",
        "AUC, ACC, _ = evaluate_model(nb_base, X_tr, y_tr, X_va, y_va)\n",
        "results_baseline[\"NaiveBayes\"] = {\"auc\": AUC, \"acc\": ACC, \"model\": nb_base}\n",
        "\n",
        "knn_base = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"pca\", PCA(n_components=60, random_state=RANDOM_STATE)),\n",
        "    (\"knn\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1, weights=\"uniform\", p=2))\n",
        "])\n",
        "AUC, ACC, _ = evaluate_model(knn_base, X_tr, y_tr, X_va, y_va)\n",
        "results_baseline[\"KNN\"] = {\"auc\": AUC, \"acc\": ACC, \"model\": knn_base}\n",
        "\n",
        "print(\"\\n== Baselines (holdout local) ==\")\n",
        "for k, v in results_baseline.items():\n",
        "    print(f\"{k:15s} | AUC: {v['auc']:.6f} | ACC: {v['acc']:.6f}\")\n",
        "\n",
        "results_tuned = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "QotVVpZ1xCE-",
        "outputId": "464b5a5c-e870-4796-e3a6-65ada68ebd11"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes -> X_full: (200000, 200) | y_full: (200000,) | X_test: (200000, 200)\n",
            "Proporção classe positiva (train): 0.1005\n",
            "Split local -> Train: (160000, 200) | Val: (40000, 200)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1917451851.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"knn\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m ])\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mresults_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"KNN\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"auc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mknn_base\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3992764485.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(clf, X_tr, y_tr, X_va, y_va)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_va\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"decision_function\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_va\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_va\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mACC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    786\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# metadata routing enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             ):\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_2d_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     return np.stack(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    867\u001b[0m         )\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    870\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \"\"\"\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             return ArgKmin64.compute(\n\u001b[0m\u001b[1;32m    282\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_original_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YkrEId0KGXZ"
      },
      "outputs": [],
      "source": [
        "def build_tree(params):\n",
        "    params = params or {}\n",
        "    return DecisionTreeClassifier(random_state=RANDOM_STATE, **params)\n",
        "\n",
        "def build_nb(params):\n",
        "    params = params or {}\n",
        "    return GaussianNB(**params)\n",
        "\n",
        "def build_knn(params):\n",
        "    params = params or {}\n",
        "    default = dict(n_jobs=-1, weights=\"uniform\", p=2)\n",
        "    default.update(params)\n",
        "    return Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"pca\", PCA(n_components=60, random_state=RANDOM_STATE)),\n",
        "        (\"knn\", KNeighborsClassifier(**default))\n",
        "    ])\n",
        "\n",
        "tree_grid = {\n",
        "    \"max_depth\": [3, 4, 5, 6, None],\n",
        "    \"min_samples_split\": [2, 10, 20, 50],\n",
        "    \"min_samples_leaf\": [1, 5, 10, 20],\n",
        "}\n",
        "nb_grid = {\"var_smoothing\": np.logspace(-12, -7, 6)}\n",
        "\n",
        "knn_grid = {\n",
        "    \"n_neighbors\": [3, 5, 9, 15],\n",
        "}\n",
        "\n",
        "print(\"\\n== Tuning (com barras de progresso) ==\")\n",
        "tree_best, tree_params, tree_cvauc = grid_search_with_tqdm(\n",
        "    build_tree, tree_grid, X_tr, y_tr, cv=3, desc=\"Grid: DecisionTree\"\n",
        ")\n",
        "nb_best, nb_params, nb_cvauc = grid_search_with_tqdm(\n",
        "    build_nb, nb_grid, X_tr, y_tr, cv=3, desc=\"Grid: NaiveBayes\"\n",
        ")\n",
        "knn_best, knn_params, knn_cvauc = grid_search_with_tqdm(\n",
        "    build_knn, knn_grid, X_tr, y_tr, cv=2, desc=\"Grid: KNN (fast)\"\n",
        ")\n",
        "\n",
        "for name, best_model, params in [\n",
        "    (\"DecisionTree\", tree_best, tree_params),\n",
        "    (\"NaiveBayes\",   nb_best,   nb_params),\n",
        "    (\"KNN\",          knn_best,  knn_params),\n",
        "]:\n",
        "    AUC, ACC, _ = evaluate_model(best_model, X_tr, y_tr, X_va, y_va)\n",
        "    results_tuned[name] = {\"auc\": AUC, \"acc\": ACC, \"model\": best_model, \"best_params\": params}\n",
        "\n",
        "print(\"\\n== Ajustados (holdout local) ==\")\n",
        "for k, v in results_tuned.items():\n",
        "    print(f\"{k:15s} | AUC: {v['auc']:.6f} | ACC: {v['acc']:.6f} | best_params={v['best_params']}\")\n",
        "\n",
        "rows = []\n",
        "for name in [\"DecisionTree\", \"NaiveBayes\", \"KNN\"]:\n",
        "    base = results_baseline[name]\n",
        "    tun  = results_tuned[name]\n",
        "    rows.append({\n",
        "        \"Algoritmo\": name,\n",
        "        \"Avaliacao Local (antes) [AUC]\": round(base[\"auc\"], 6),\n",
        "        \"Kaggle (antes) [AUC]\": \"\",\n",
        "        \"Avaliacao Local (ajustado) [AUC]\": round(tun[\"auc\"], 6),\n",
        "        \"Kaggle (ajustado) [AUC]\": \"\"\n",
        "    })\n",
        "scores_df = pd.DataFrame(rows)\n",
        "scores_df.to_csv(\"tabela_comparativa_local_vs_kaggle.csv\", index=False)\n",
        "print(\"\\nTabela salva em: tabela_comparativa_local_vs_kaggle.csv\")\n",
        "display(scores_df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_submission(model, X_train_full, y_train_full, X_test, id_series, fname):\n",
        "    model.fit(X_train_full, y_train_full)\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        preds = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        preds = model.predict(X_test).astype(float)\n",
        "    sub = pd.DataFrame({\"ID_code\": id_series, \"target\": preds})\n",
        "    sub.to_csv(fname, index=False)\n",
        "    return fname\n",
        "\n",
        "print(\"\\n== Gerando submissões (com tqdm) ==\")\n",
        "subs_info = []\n",
        "subs_info.append(make_submission(DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=3),\n",
        "                                 X_full, y_full, X_test, id_test, \"sub_decisiontree_baseline.csv\"))\n",
        "subs_info.append(make_submission(GaussianNB(),\n",
        "                                 X_full, y_full, X_test, id_test, \"sub_naivebayes_baseline.csv\"))\n",
        "subs_info.append(make_submission(Pipeline([\n",
        "                                     (\"scaler\", StandardScaler()),\n",
        "                                     (\"pca\", PCA(n_components=60, random_state=RANDOM_STATE)),\n",
        "                                     (\"knn\", KNeighborsClassifier(n_neighbors=5, n_jobs=-1, weights=\"uniform\", p=2))\n",
        "                                 ]),\n",
        "                                 X_full, y_full, X_test, id_test, \"sub_knn_baseline.csv\"))\n",
        "subs_info.append(make_submission(results_tuned[\"DecisionTree\"][\"model\"],\n",
        "                                 X_full, y_full, X_test, id_test, \"sub_decisiontree_tuned.csv\"))\n",
        "subs_info.append(make_submission(results_tuned[\"NaiveBayes\"][\"model\"],\n",
        "                                 X_full, y_full, X_test, id_test, \"sub_naivebayes_tuned.csv\"))\n",
        "subs_info.append(make_submission(results_tuned[\"KNN\"][\"model\"],\n",
        "                                 X_full, y_full, X_test, id_test, \"sub_knn_tuned.csv\"))\n",
        "\n",
        "for f in subs_info:\n",
        "    print(\"Gerado:\", f)\n",
        "\n",
        "dump(results_tuned[\"DecisionTree\"][\"model\"], \"best_decision_tree.joblib\")\n",
        "dump(results_tuned[\"NaiveBayes\"][\"model\"],   \"best_naive_bayes.joblib\")\n",
        "dump(results_tuned[\"KNN\"][\"model\"],          \"best_knn.joblib\")\n",
        "print(\"\\nModelos salvos: best_decision_tree.joblib, best_naive_bayes.joblib, best_knn.joblib\")\n",
        "\n",
        "best_name = max(results_tuned, key=lambda k: results_tuned[k][\"auc\"])\n",
        "comment = (\n",
        "    f\"No holdout local, o melhor AUC foi do {best_name} (ajustado). \"\n",
        "    \"O ajuste de hiperparâmetros elevou o AUC em relação aos baselines, \"\n",
        "    \"mostrando sensibilidade a profundidade (árvore), vizinhos/peso/distância (kNN) \"\n",
        "    \"e var_smoothing (Naive Bayes). \"\n",
        "    \"Se o score no Kaggle divergir, causas prováveis são diferença de distribuição \"\n",
        "    \"entre o holdout local e o teste público/privado ou overfitting aos hiperparâmetros.\"\n",
        ")\n",
        "with open(\"comentario_resultados.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(comment)\n",
        "print(\"\\ncomentario_resultados.txt:\\n\", comment)\n",
        "\n",
        "print(\"\\nPronto. Submeta os 6 CSVs ao Kaggle e preencha as colunas 'Kaggle (antes/ajustado)' na tabela gerada.\")"
      ],
      "metadata": {
        "id": "nMwCTtLGxHyu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}